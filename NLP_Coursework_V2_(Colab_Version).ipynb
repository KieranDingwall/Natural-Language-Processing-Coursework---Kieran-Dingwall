{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KieranDingwall/Natural-Language-Processing-Coursework---Kieran-Dingwall/blob/main/NLP_Coursework_V2_(Colab_Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b40ace",
      "metadata": {
        "id": "47b40ace"
      },
      "source": [
        "# Natural Language Processing Coursework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5dba9e",
      "metadata": {
        "id": "8f5dba9e"
      },
      "source": [
        "By Kieran Dingwall - Student Number: 2208619"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1528fb70",
      "metadata": {
        "id": "1528fb70"
      },
      "source": [
        "### Section 1 - Dataset Exploring and Pre Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: https://archive.ics.uci.edu/dataset/837/product+classification+and+clustering"
      ],
      "metadata": {
        "id": "rOE6kfWi_PR-"
      },
      "id": "rOE6kfWi_PR-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my classification model, I will be using the ‘Product Classification and Clustering’ dataset that can be found on ‘UC Irvine Machine Learning Repository’. This dataset was taken from pricerunner, which is a popular product comparison platform. The dataset includes 35311 products in 10 different categories from 306 different merchants. The aim is to train the model to recognise different products and predict what product category they belong too."
      ],
      "metadata": {
        "id": "8CsLVUbC-0G7"
      },
      "id": "8CsLVUbC-0G7"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1dfaab51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dfaab51",
        "outputId": "d66d9fb9-6aea-4043-e495-b151a5d86b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "       Product ID  ...  Category Label\n",
            "0               1  ...   Mobile Phones\n",
            "1               2  ...   Mobile Phones\n",
            "2               3  ...   Mobile Phones\n",
            "3               4  ...   Mobile Phones\n",
            "4               5  ...   Mobile Phones\n",
            "...           ...  ...             ...\n",
            "35306       47350  ...         Fridges\n",
            "35307       47351  ...         Fridges\n",
            "35308       47352  ...         Fridges\n",
            "35309       47355  ...         Fridges\n",
            "35310       47358  ...         Fridges\n",
            "\n",
            "[35311 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load Dataset\n",
        "from google.colab import files, drive #import colab functionality\n",
        "drive.mount(\"/content/drive\")\n",
        "# Path to where mine is - This will need changed\n",
        "path = '/content/drive/MyDrive/Uni/4th Year 1st Sem/Natural Language Processing/NLP Coursework/pricerunner_aggregate.csv'\n",
        "product_data = pd.read_csv(path)\n",
        "print(product_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4d101a63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d101a63",
        "outputId": "b2ca982b-bb88-4c3b-b0c0-48537a1cd06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Product Title  ...  Category Label\n",
            "0                        apple iphone 8 plus 64gb silver  ...   Mobile Phones\n",
            "1                    apple iphone 8 plus 64 gb spacegrau  ...   Mobile Phones\n",
            "2      apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...  ...   Mobile Phones\n",
            "3                    apple iphone 8 plus 64gb space grey  ...   Mobile Phones\n",
            "4      apple iphone 8 plus gold 5.5 64gb 4g unlocked ...  ...   Mobile Phones\n",
            "...                                                  ...  ...             ...\n",
            "35306  smeg fab28 60cm retro style right hand hinge f...  ...         Fridges\n",
            "35307  smeg fab28 60cm retro style left hand hinge fr...  ...         Fridges\n",
            "35308  smeg fab28 60cm retro style left hand hinge fr...  ...         Fridges\n",
            "35309     candy 60cm built under larder fridge cru160nek  ...         Fridges\n",
            "35310           neff k4316x7gb built under larder fridge  ...         Fridges\n",
            "\n",
            "[35311 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Remove unused columns from data\n",
        "product_df = product_data.drop(product_data.columns[[0, 2, 3, 5]], axis=1)\n",
        "print(product_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring the dataset, there are 7 columns of data including Product ID, Product Title, Merchant ID, Cluster ID, Cluster Label, Category ID and Category Label. Most of these columns I will not need for the task so I decided to drop them from the dataframe leaving me the 2 necessary columns for my task, ‘Product Title’ and ‘Category Label’."
      ],
      "metadata": {
        "id": "Ppvdjy9--6_b"
      },
      "id": "Ppvdjy9--6_b"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ad46de17",
      "metadata": {
        "id": "ad46de17"
      },
      "outputs": [],
      "source": [
        "# Convert the feature columns into numpy array's\n",
        "x = product_df[\"Product Title\"].to_numpy()\n",
        "y = product_df[\" Category Label\"].to_numpy()\n",
        "\n",
        "# Testing outputs\n",
        "#print(x)\n",
        "#print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the data in the ‘Product Title’ column, there are titles ranging from Iphones to washing machines, however, these titles also have extra information that won’t be needed and will be sorted in the pre-processing method. For example, from ‘sony hx400v compact camera with 50x optical zoom’, the keywords such as ‘camera’ should be pushed. As for ‘Category Label’, there are 10 different labels under the column including Mobile Phones, Fridge Freezers, Washing Machines, CPUs, Fridges, TVs, Dishwashers, Digital Cameras, Microwaves and Freezers."
      ],
      "metadata": {
        "id": "JwkOlliCN4-b"
      },
      "id": "JwkOlliCN4-b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d9c2d08f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9c2d08f",
        "outputId": "9f952a1c-2316-425f-894a-fba4c0ff3f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Title\n",
            "washing machine                                     90\n",
            "built in fully integrated dishwasher                35\n",
            "frost free fridge freezer                           34\n",
            "washer dryer                                        24\n",
            "american fridge freezer                             22\n",
            "                                                    ..\n",
            "sony rx10 ii bridgekamera 1 dscrx10m2                1\n",
            "sony hx400v compact camera with 50x optical zoom     1\n",
            "sony hx400 20mp 50x zoom bridge camera               1\n",
            "sony cyber shot hx400 digital camera                 1\n",
            "sony a7 iii body                                     1\n",
            "Name: count, Length: 30993, dtype: int64\n",
            " Category Label\n",
            "Fridge Freezers     5501\n",
            "Mobile Phones       4081\n",
            "Washing Machines    4044\n",
            "CPUs                3862\n",
            "Fridges             3584\n",
            "TVs                 3564\n",
            "Dishwashers         3424\n",
            "Digital Cameras     2697\n",
            "Microwaves          2342\n",
            "Freezers            2212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking Balance as well as seeing the data to work with\n",
        "\n",
        "print(product_df[\"Product Title\"].value_counts())\n",
        "print(product_df[\" Category Label\"].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For pre-processing, I chose to use tokenisation and lemmatizer. I initially used stemming, utilising the snowball stemmer, but found that it just took away letters from the end of words rather than finding a more common alternative for that word, making it not very effective. With the lemmatizer, it uses a detailed dictionary of pre-defined words to always make sure a relevant and more common alternative to each word is returned. This proved to be much more accurate when looking through a sample of the data after going through both pre-processing methods separately."
      ],
      "metadata": {
        "id": "mmfAYPiY_Fk_"
      },
      "id": "mmfAYPiY_Fk_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing using tokenisation and lemmatizer\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def prep(X):\n",
        "  prep_text = []\n",
        "  wnl = WordNetLemmatizer() # Initialise Lemmatizer\n",
        "  for x in X:\n",
        "        token_text = word_tokenize(x)\n",
        "        normd_text = [token.lower() for token in token_text if token.isalpha()]\n",
        "\n",
        "        swr_text = [token for token in normd_text if token not in stopwords.words('english')]\n",
        "\n",
        "        prep_text += [[wnl.lemmatize(word, pos=\"v\") for word in swr_text]]\n",
        "\n",
        "  prep_sentences = [\" \".join(sentence) for sentence in prep_text]\n",
        "  return prep_sentences\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxkNcP-3xq0e",
        "outputId": "0e853c91-cde4-4796-a1c5-444fadad1a6c"
      },
      "id": "kxkNcP-3xq0e",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4b0061",
      "metadata": {
        "id": "ee4b0061"
      },
      "source": [
        "### Section 2 - Representation Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my representation learner, I have decided to use TfidfVectorizer from the SKLearn language toolkit. It is commonly used to convert collections of raw data into a matrix of TF-IDF. It starts by tokenizing the text, splitting it into words or n-grams, then builds a vocabulary of known words allowing for each word to be given an TF-IDF score, which suggests how relevant each word is, and outputs a sparse matrix that can be used by pipelines or models. This works for my dataset as it highlights the important words that are in each product title. For example, for the record ‘apple iphone 8 plus 64gb silver’, it would find the important word phone, as well as weighing down more less important common words found in multiple titles such as ‘plus’ which makes it easier for it to be classified in the category ‘Mobile Phones’.  "
      ],
      "metadata": {
        "id": "J4n4xXPkaqg3"
      },
      "id": "J4n4xXPkaqg3"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e42e6ead",
      "metadata": {
        "id": "e42e6ead"
      },
      "outputs": [],
      "source": [
        "# Representation Learner - Vectorising\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_base = TfidfVectorizer(max_features=2000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7562a92c",
      "metadata": {
        "id": "7562a92c"
      },
      "source": [
        "### Section 3 - Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithm 1 - K-Nearest Neighbour (kNN)\n",
        "\n",
        "kNN is an algorithm used for text classification and works on a similarity based method. A kNN algorithm is designed to predict the label of data points based on the labels of its k closest neighbours, k being the amount of neighbours it checks. For my model, I build this into a pipeline which also uses my pre-processing function and representation learner. The kNN then measures the distance from the current data point to all other points in the training set. After this it sorts the training points by distance and selects the k closest neighbours. Finally, the model predicts the label of each product by taking a majority vote between the k neighbour labels and returns the predicted label for the product. I decided to use a grid search for my kNN which went through each number of neighbours and parameters to make the model as accurate as possible. I chose kNN as one of my models because it is able to naturally handle multi-class problems while still being simple and fast and fits the dataset well as most products have similar words in their title to their respective labels.\n"
      ],
      "metadata": {
        "id": "__9mzYxOo2qJ"
      },
      "id": "__9mzYxOo2qJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Warning: The code below has been commented out as it takes 1 hour to run, testing over 30 models, so a ‘quicker version’ with the best params and neighbours hardcoded can be found directly underneath this block and is labelled with a comment. To see output feel free to uncomment."
      ],
      "metadata": {
        "id": "tVRyzaCLbsV3"
      },
      "id": "tVRyzaCLbsV3"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "93c5e230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "93c5e230",
        "outputId": "43305789-fcff-443c-dc95-d953113f34ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Testing with K-Nearest Neighbour in a pipeline\\n\\n# SKLearn Imports\\nfrom sklearn.model_selection import StratifiedKFold\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.feature_extraction.text import TfidfTransformer\\nfrom sklearn.svm import SVC\\nfrom sklearn.preprocessing import FunctionTransformer\\nfrom sklearn.model_selection import GridSearchCV\\n\\n\\n\\nknn_acc_score = []\\n\\n# Creates a FunctionTransformer for the prep function\\nprep_transformer = FunctionTransformer(prep, validate=False)\\n\\npipeline = Pipeline([\\n  (\\'prep\\', prep_transformer),\\n  (\\'rep\\', TfidfVectorizer()),\\n  (\\'mod\\', KNeighborsClassifier(n_neighbors=3))\\n])\\n\\n# Using GridSearch to find best parameters for pipeline\\n# Define parameter grid for GridSearch\\nparam_grid = {\\n    \\'mod__n_neighbors\\': [1, 3, 5, 7, 9],\\n    \\'mod__weights\\': [\\'uniform\\', \\'distance\\'],\\n    \\'mod__metric\\': [\\'euclidean\\', \\'manhattan\\', \\'cosine\\']\\n}\\n\\nkf = StratifiedKFold(n_splits=5)\\n\\ngrid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring=\\'accuracy\\', n_jobs=1)\\ngrid_search.fit(x, y)\\n\\nprint(\"Best Parameters:\", grid_search.best_params_)\\nprint(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "# Testing with K-Nearest Neighbour in a pipeline\n",
        "\n",
        "# SKLearn Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n",
        "knn_acc_score = []\n",
        "\n",
        "# Creates a FunctionTransformer for the prep function\n",
        "prep_transformer = FunctionTransformer(prep, validate=False)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('prep', prep_transformer),\n",
        "  ('rep', TfidfVectorizer()),\n",
        "  ('mod', KNeighborsClassifier(n_neighbors=3))\n",
        "])\n",
        "\n",
        "# Using GridSearch to find best parameters for pipeline\n",
        "# Define parameter grid for GridSearch\n",
        "param_grid = {\n",
        "    'mod__n_neighbors': [1, 3, 5, 7, 9],\n",
        "    'mod__weights': ['uniform', 'distance'],\n",
        "    'mod__metric': ['euclidean', 'manhattan', 'cosine']\n",
        "}\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='accuracy', n_jobs=1)\n",
        "grid_search.fit(x, y)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validated Accuracy:\", grid_search.best_score_)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with K-Nearest Neighbour in a pipeline (Quicker version)\n",
        "# Gemini used to help with error handling\n",
        "# SKLearn Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "knn_acc_score = []\n",
        "knn_f1_score = []\n",
        "\n",
        "# Creates a FunctionTransformer for the prep function\n",
        "prep_transformer = FunctionTransformer(prep, validate=False)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('prep', prep_transformer),\n",
        "  ('rep', TfidfVectorizer()),\n",
        "  ('mod', KNeighborsClassifier(n_neighbors=9, weights='distance', metric='cosine'))\n",
        "])\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for train, test in kf.split(x,y):\n",
        "  x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]\n",
        "\n",
        "  pipeline.fit(x_train, y_train)\n",
        "  predictions = pipeline.predict(x_test)\n",
        "  acc = accuracy_score(predictions, y_test)\n",
        "  f1 = f1_score(y_test, predictions, average='macro')\n",
        "  knn_acc_score.append(acc)\n",
        "  knn_f1_score.append(f1)\n",
        "\n",
        "print(\"Accuracy:\", np.mean(knn_acc_score))\n",
        "print(\"F1 Score:\", np.mean(knn_f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmicsxRvaeCg",
        "outputId": "8475792e-3712-42e8-b3e6-00d7220d72d7"
      },
      "id": "pmicsxRvaeCg",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8908551041596622\n",
            "F1 Score: 0.888517170247345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithm 2 - Multi-Layer Perception (MLP)\n",
        "\n",
        "A MLP is a type of neural algorithm which gets built up by many different neural layers. It is commonly used for text classification tasks like this one. The one that I use is a sequential model which means each layer is run in order of how they are coded. I decided on 3 layers, the first one being the input layer. The input layer takes the raw data values, which in my case is the TF-IDF scores from my representation learner. I have then used a hidden layer where a weighted sum is used to perform a ‘relu’ function. Finally, there is the output layer which produces a final prediction using softmax activation. I then use the model for testing by looping through the arrays and running the model on each data point.\n"
      ],
      "metadata": {
        "id": "v-ZybqD4o4TX"
      },
      "id": "v-ZybqD4o4TX"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "519e871e",
      "metadata": {
        "id": "519e871e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06f1ffc-5da2-47aa-a412-f5007ea7bde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6202 - loss: 1.7756 - val_accuracy: 0.3366 - val_loss: 3.7762\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9655 - loss: 0.1381 - val_accuracy: 0.4044 - val_loss: 4.4717\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9735 - loss: 0.0861 - val_accuracy: 0.4112 - val_loss: 4.8442\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.0723 - val_accuracy: 0.4253 - val_loss: 4.9832\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9759 - loss: 0.0671 - val_accuracy: 0.4142 - val_loss: 5.1790\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9765 - loss: 0.0647 - val_accuracy: 0.4196 - val_loss: 5.3366\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.0636 - val_accuracy: 0.4200 - val_loss: 5.3966\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9749 - loss: 0.0656 - val_accuracy: 0.4156 - val_loss: 5.4694\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9731 - loss: 0.0676 - val_accuracy: 0.4182 - val_loss: 5.4555\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.0632 - val_accuracy: 0.4223 - val_loss: 5.5741\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9721 - loss: 0.1384\n",
            "Test results - Loss: 1.2088383436203003 - Accuracy: 0.8553022742271423%\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6438 - loss: 1.7592 - val_accuracy: 0.3699 - val_loss: 3.9485\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9658 - loss: 0.1354 - val_accuracy: 0.4058 - val_loss: 4.6905\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9741 - loss: 0.0825 - val_accuracy: 0.4028 - val_loss: 5.0115\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9756 - loss: 0.0728 - val_accuracy: 0.4011 - val_loss: 5.2276\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9755 - loss: 0.0718 - val_accuracy: 0.4046 - val_loss: 5.4363\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9754 - loss: 0.0685 - val_accuracy: 0.4106 - val_loss: 5.5495\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9766 - loss: 0.0654 - val_accuracy: 0.4200 - val_loss: 5.6740\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9776 - loss: 0.0628 - val_accuracy: 0.3986 - val_loss: 5.7978\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9763 - loss: 0.0644 - val_accuracy: 0.4051 - val_loss: 5.7853\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9773 - loss: 0.0631 - val_accuracy: 0.3938 - val_loss: 5.8462\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9734 - loss: 0.1293\n",
            "Test results - Loss: 1.2412794828414917 - Accuracy: 0.8528745174407959%\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5918 - loss: 1.7676 - val_accuracy: 0.3481 - val_loss: 3.9719\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9624 - loss: 0.1401 - val_accuracy: 0.4000 - val_loss: 4.5692\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9711 - loss: 0.0862 - val_accuracy: 0.4011 - val_loss: 4.9085\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9761 - loss: 0.0685 - val_accuracy: 0.4087 - val_loss: 5.1119\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9722 - loss: 0.0751 - val_accuracy: 0.4127 - val_loss: 5.3109\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9736 - loss: 0.0687 - val_accuracy: 0.4064 - val_loss: 5.4614\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9753 - loss: 0.0635 - val_accuracy: 0.4035 - val_loss: 5.3709\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0650 - val_accuracy: 0.4078 - val_loss: 5.5958\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9749 - loss: 0.0658 - val_accuracy: 0.4030 - val_loss: 5.7398\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9723 - loss: 0.0674 - val_accuracy: 0.4106 - val_loss: 5.7542\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.1195\n",
            "Test results - Loss: 1.1957952976226807 - Accuracy: 0.862645149230957%\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6122 - loss: 1.7717 - val_accuracy: 0.3674 - val_loss: 3.9405\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9667 - loss: 0.1295 - val_accuracy: 0.3959 - val_loss: 4.7600\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9731 - loss: 0.0811 - val_accuracy: 0.4117 - val_loss: 5.1987\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9737 - loss: 0.0744 - val_accuracy: 0.4112 - val_loss: 5.3655\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.0685 - val_accuracy: 0.4143 - val_loss: 5.5970\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9740 - loss: 0.0692 - val_accuracy: 0.3968 - val_loss: 5.7719\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9731 - loss: 0.0706 - val_accuracy: 0.4108 - val_loss: 5.8905\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9759 - loss: 0.0624 - val_accuracy: 0.4145 - val_loss: 5.9591\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9742 - loss: 0.0639 - val_accuracy: 0.4099 - val_loss: 6.0276\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9758 - loss: 0.0614 - val_accuracy: 0.4106 - val_loss: 6.1645\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.1392\n",
            "Test results - Loss: 1.291845440864563 - Accuracy: 0.8620787262916565%\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6225 - loss: 1.7770 - val_accuracy: 0.3763 - val_loss: 3.7604\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9669 - loss: 0.1370 - val_accuracy: 0.3834 - val_loss: 4.5809\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9712 - loss: 0.0835 - val_accuracy: 0.4057 - val_loss: 4.8727\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9727 - loss: 0.0737 - val_accuracy: 0.4083 - val_loss: 5.1268\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9749 - loss: 0.0703 - val_accuracy: 0.4182 - val_loss: 5.2197\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9753 - loss: 0.0650 - val_accuracy: 0.4181 - val_loss: 5.4279\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9777 - loss: 0.0610 - val_accuracy: 0.4150 - val_loss: 5.5704\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.9751 - loss: 0.0604 - val_accuracy: 0.4244 - val_loss: 5.6733\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9750 - loss: 0.0643 - val_accuracy: 0.4106 - val_loss: 5.6703\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9761 - loss: 0.0615 - val_accuracy: 0.4239 - val_loss: 5.7868\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.1375\n",
            "Test results - Loss: 1.2412105798721313 - Accuracy: 0.8549985885620117%\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Accuracy: 0.8575798511505127\n",
            "F1 Score: 0.8201656612855024\n"
          ]
        }
      ],
      "source": [
        "# Testing with Multi Layer Perception to compare accuracy scores\n",
        "# Gemini used to help with error handling\n",
        "# Tensorflow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# SKLearn Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def mlp(input_dimension, num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_shape=(input_dimension,), activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "xnp = np.array(x) #convert to numpy to standardise the arrays for the split\n",
        "ynp = np.array(y)\n",
        "\n",
        "# Define NUM_CLASSES and label_to_int mapping\n",
        "unique_labels = np.unique(ynp)\n",
        "NUM_CLASSES = len(unique_labels)\n",
        "label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Define TFIDF_MAX_FEATURES\n",
        "TFIDF_MAX_FEATURES = tfidf_base.max_features\n",
        "\n",
        "mlp_acc_score = []\n",
        "mlp_f1_score = []\n",
        "\n",
        "for train, test in kf.split(xnp,ynp):\n",
        "  x_train, x_test, y_train, y_test = xnp[train], xnp[test], ynp[train], ynp[test]\n",
        "\n",
        "  # preprocess our train and test datasets\n",
        "  x_train = prep(x_train)\n",
        "  x_test = prep(x_test)\n",
        "\n",
        "  # Instantiate TfidfVectorizer for each fold to prevent data leakage\n",
        "  tfidf_vectorizer = tfidf_base\n",
        "  x_train = tfidf_vectorizer.fit_transform(x_train)\n",
        "  x_train = x_train.todense()\n",
        "  x_test = tfidf_vectorizer.transform(x_test)\n",
        "  x_test = x_test.todense()\n",
        "\n",
        "  # Encode string labels to integers before one-hot encoding\n",
        "  y_train_encoded = np.array([label_to_int[label] for label in y_train])\n",
        "  y_test_encoded = np.array([label_to_int[label] for label in y_test])\n",
        "\n",
        "  model = mlp(TFIDF_MAX_FEATURES, NUM_CLASSES)\n",
        "  y_train_one_hot = to_categorical(y_train_encoded, NUM_CLASSES)\n",
        "  y_test_one_hot = to_categorical(y_test_encoded, NUM_CLASSES)\n",
        "\n",
        "  # Configure the model and start training\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train_one_hot, epochs=10, batch_size=250, verbose=1, validation_split=0.2)\n",
        "\n",
        "  # Test the model after training\n",
        "  test_results = model.evaluate(x_test, y_test_one_hot, verbose=1)\n",
        "  print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
        "\n",
        "  # Predict F1\n",
        "  y_pred_probs = model.predict(x_test)\n",
        "  y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "  f1 = f1_score(y_test_encoded, y_pred_labels, average='macro')\n",
        "\n",
        "  mlp_acc_score.append(test_results[1])\n",
        "  mlp_f1_score.append(f1)\n",
        "\n",
        "print(\"Accuracy:\", np.mean(mlp_acc_score))\n",
        "print(\"F1 Score:\", np.mean(mlp_f1_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd7583e0",
      "metadata": {
        "id": "cd7583e0"
      },
      "source": [
        "### Section 4 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at each algorithm’s performance, the kNN algorithm produced an accuracy score of 0.851, however had a wider range of scores from 0.80 to 0.88, making it a slightly inconsistent model. However, the MLP model had a very similar average score with roughly 0.859, but was a more consistent model giving similar scores for each run."
      ],
      "metadata": {
        "id": "ar5buETxo-CU"
      },
      "id": "ar5buETxo-CU"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6683c333",
      "metadata": {
        "id": "6683c333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "2225fc70-a894-4658-c97d-a2fb65be835a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(1, 0, 'knn'), Text(2, 0, 'mlp')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAG/CAYAAAB7bYyZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPOhJREFUeJzt3X1cVGX+//H3MMqNN6Am4h2JdwHeJILJipa5S5omm22Wq6sipWabWWL1RQN19adsdyxtYlqb5oqm3ZDblqtbqFtubhZUW5so5l1LglophorJXL8/fDDtxKAOonPA1/PxOI+a61znOp8zoPP2nOucsRljjAAAACzMx9sFAAAAnA+BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBQAAWB6BBXWGzWbT3Llzvbb/sLAwTZgw4YL7Dh8+/NIWZBElJSUaOXKkrrrqKtlsNmVmZnq7pDrl5ZdfVosWLfT99997u5Q66ZtvvlHjxo21fv16b5eCS4zAAktYvHixbDabYmNjvV3KBfviiy80d+5c7du3z9ulVHHjjTfKZrM5lxYtWui6667TsmXL5HA4anVf06dP18aNGzVz5kytXLlSN998c62OX59VVFRozpw5uv/++9WkSRO369u2bSubzaa//e1vXqjQ+q666ipNnDhRaWlp3i4FlxiBBZawatUqhYWFafv27dq9e7e3y3Fr586dev75552vv/jiC/3ud7+zZGCRpPbt22vlypVauXKl0tLSdObMGd19992aNWtWre5n06ZNuvXWW/XQQw9p7NixioiIqNXx67O//vWv2rlzpyZPnux2/aZNm3Tw4EGFhYVp1apVl7m6umPKlCnKz8/Xpk2bvF0KLiECC7xu7969ev/995WRkaHg4GBL/cVsjNHJkyclSX5+fmrYsKGXK7pwQUFBGjt2rMaOHavp06frn//8p9q3b69Fixbphx9+uKixz5w5o9OnT0uSDh06pGbNmtVCxWedOnWq1s8CWdXy5cvVv39/tWvXzu367OxsRUdHa/r06Vq3bp3Kysouc4UX5n9/H7whMjJSPXr00Isvvui1GnDpEVjgdatWrVLz5s11yy23aOTIkR4Fli1btqhPnz7y9/dX586dtXTpUs2dO1c2m82l35kzZzR//nx17txZfn5+CgsL06xZs1ReXu7Sr3LuycaNG9WnTx8FBARo6dKlznWVc1hefPFF3XHHHZKkQYMGOS+9bNmyxWW8rVu3qm/fvvL391enTp305z//2WX9iy++KJvNpq1bt2ratGkKDg5Ws2bNdM899+j06dM6evSoxo8fr+bNm6t58+Z65JFHVNMvWG/UqJF+9rOfqaysTIcPH5YkHT16VA8++KBCQ0Pl5+enLl266LHHHnMJDPv27ZPNZtOTTz6pzMxM53tYeRnPGKOsrCzne1Bpz549uuOOO9SiRQvnvt966y2XmrZs2SKbzaY1a9YoNTVV7dq1U6NGjVRaWqoJEyaoSZMmOnDggIYPH64mTZqoXbt2ysrKkiR99tln+vnPf67GjRurQ4cOWr16tcvY3377rR566CH17NlTTZo0UWBgoIYOHapPP/3UbQ0vv/yyFixYoPbt28vf31+/+MUv3J7t++CDDzRs2DA1b95cjRs31rXXXqunn37apU9BQYFGjhypFi1ayN/fX3369NEbb7zh0ufUqVPasGGD4uPj3f68Tp48qddff12//vWvdeedd+rkyZP6y1/+4rbv3/72Nw0cOFBNmzZVYGCgrrvuuirvx/nqvvHGG3XjjTdWGXvChAkKCwtzvq7u9+GLL77Q6dOnNXv2bMXExCgoKEiNGzfW9ddfr82bN1cZ1+Fw6Omnn1bPnj3l7++v4OBg3Xzzzfroo48kSQMHDlSvXr3cHm94eLiGDBni0nbTTTfpr3/9a43/fKAOMICXRUREmLvvvtsYY8y7775rJJnt27dX6SfJzJkzx/k6Pz/f+Pn5mbCwMPP73//eLFiwwLRt29b06tXL/PRXOzEx0UgyI0eONFlZWWb8+PFGkhkxYoRLvw4dOpguXbqY5s2bm5SUFLNkyRKzefNm57rExERjjDFffvmlmTZtmpFkZs2aZVauXGlWrlxpiouLnX3Dw8NNSEiImTVrllm0aJGJjo42NpvNfP755879LV++3EgyUVFR5uabbzZZWVlm3LhxRpJ55JFHzIABA8yYMWPM4sWLzfDhw40ks2LFivO+pwMHDjTdu3ev0h4dHW3sdrspKyszZWVl5tprrzVXXXWVmTVrllmyZIkZP368sdls5oEHHnBus3fvXiPJdOvWzXTq1Mn8/ve/N3/4wx/MP/7xD7Ny5Uojydx0003O98AYY4qLi01ISIhp2rSpefTRR01GRobp1auX8fHxMTk5Oc6xN2/e7Bw7KirKZGRkmPT0dFNWVmYSExONv7+/6datm5kyZYrJysoycXFxRpJZvny5adu2rXn44YfNM888Y7p3727sdrvZs2ePc+wPP/zQdO7c2aSkpJilS5eaefPmmXbt2pmgoCBTVFRUpYbevXubmJgY84c//MHMnTvXNGrUyPTt29fl/fv73/9ufH19TYcOHcycOXPMs88+a6ZNm2bi4+OdfT7//HMTFBRkunXrZh577DGzaNEic8MNNxibzeZy7Fu3bjWSzBtvvOH2Z7hmzRpjs9nMgQMHjDHG/PznPzfDhg2r0m/58uXGZrOZHj16mAULFpisrCwzceJEM27cOI/qHjhwoBk4cGCV8RMTE02HDh3O+/uwf/9+c/jwYdOmTRuTnJxsnn32WfP444+b8PBw07BhQ/Pxxx+7jDthwgQjyQwdOtRkZmaaJ5980tx6663mmWeeMcYY8/zzzxtJ5rPPPnPZbvv27UaS+fOf/+zSnp2d7bY/6g8CC7zqo48+MpLM22+/bYwxxuFwmPbt27t8YFb6aWBJSEgwjRo1cvnwKSwsNA0aNHAJLJ988omRZCZOnOgy3kMPPWQkmU2bNjnbOnToYCSZDRs2VNn//wYWY4x55ZVXjCRnoPlpX0nm3XffdbYdOnTI+Pn5mRkzZjjbKgPLkCFDjMPhcLb369fP2Gw2M2XKFGfbmTNnTPv27d1+qPzUwIEDTUREhDl8+LA5fPiw2bFjhzNgJSQkGGOMmT9/vmncuLHZtWuXy7YpKSnGbrc7PygrP6ACAwPNoUOHquxLkrnvvvtc2h588EEjybz33nvOtuPHj5uOHTuasLAwU1FRYYz5MSx06tTJnDhxwmWMypC5cOFCZ9t3331nAgICjM1mM2vWrHG2FxQUVPn9OHXqlHM/lfbu3Wv8/PzMvHnznG2VNURGRpry8nJn+9NPP+3yAXjmzBnTsWNH06FDB/Pdd9+5jPu/P7tf/OIXpmfPnubUqVMu6+Pi4kzXrl2dbX/605/O+QE7fPhw079/f+fr5557zjRo0MDlZ3D06FHTtGlTExsba06ePOm2pgut29PA4u734cyZMy7voTFnf2YhISHmrrvucrZt2rTJSDLTpk2rsr/Kmo4ePWr8/f3N//3f/7msnzZtmmncuLH5/vvvXdrff/99I8msXbu2ypioH7gkBK9atWqVQkJCNGjQIElnb10eNWqU1qxZo4qKimq3q6io0DvvvKMRI0aobdu2zvYuXbpo6NChLn0rb3dMTk52aZ8xY4YkVblM0bFjxyqnm2uiW7duuv76652vg4ODFR4erj179lTpe/fdd7tcTomNjZUxRnfffbezzW63q0+fPm63d6egoEDBwcEKDg5WZGSknnnmGd1yyy1atmyZJOmVV17R9ddfr+bNm+vIkSPOJT4+XhUVFXr33Xddxrv99tsVHBx8Qftev369+vbtqwEDBjjbmjRposmTJ2vfvn364osvXPonJiYqICDA7VgTJ050/n+zZs0UHh6uxo0b684773S2h4eHq1mzZi7vjZ+fn3x8zv4VV1FRoW+++UZNmjRReHi48vPzq+wnKSlJvr6+zteVP7vKMT/++GPt3btXDz74YJU5O5U/u2+//VabNm3SnXfeqePHjzvf02+++UZDhgxRYWGhioqKJJ29HVeSmjdvXqWWb775Rhs3btTo0aOdbbfffrvz0lWlt99+W8ePH1dKSor8/f3d1nQhddeEu98Hu93ufA8dDoe+/fZbnTlzRn369HF5z1977TXZbDbNmTOnyriVNQUFBenWW2/VSy+95LzMU1FRobVr12rEiBFq3Lixy3aV7+ORI0dqfEywtgbeLgBXroqKCq1Zs0aDBg3S3r17ne2xsbF66qmnlJubq8GDB7vd9tChQzp58qS6dOlSZd1P2/bv3y8fH58q7a1bt1azZs20f/9+l/aOHTvW9JBcXH311VXamjdvru++++68fYOCgiRJoaGhVdrdbe9OWFiYnn/+edlsNvn7+6tr165q1aqVc31hYaH+/e9/VxtCDh065PLak/dl//79bm9Rj4yMdK7v0aPHeceunNvwv4KCgtS+ffsqH7Y/fW8q50gsXrxYe/fudQnAV111VZV9/fRnUPkBWDnml19+KUkudf/U7t27ZYxRWlpatbfZHjp0yGWSrXEz52Lt2rX64Ycf1Lt3b5d5NLGxsVq1apXuu+++C67pQvrURHU/sxUrVuipp55SQUGBy+Tu/+3/5Zdfqm3btmrRosU59zF+/HitXbtW7733nm644Qa98847Kikp0bhx46r0rXwfLyaEwdoILPCayls216xZozVr1lRZv2rVqmoDS01c6F9k1f1L31N2u91tu7sPqOr6umt3t707jRs3rnZCp3T2A/2mm27SI4884nb9Nddc4/K6tt4Xd6ob25P3RXJ9bxYuXKi0tDTdddddmj9/vlq0aCEfHx89+OCDbu9C8uTnVZ3KcR966KFqz9JVBufK0PTdd9+pffv2Ln0qJ57379/f7Rh79uxRp06dLriuC1E5gfqnqjvT6e5nlp2drQkTJmjEiBF6+OGH1apVK9ntdqWnpzuDkyeGDBmikJAQZWdn64YbblB2drZat27t9ve6Mli2bNnS4/2gbiCwwGtWrVqlVq1aOe/6+F85OTl6/fXXtWTJErd/MbZq1Ur+/v5u7+L4aVuHDh3kcDhUWFjo/Be+dPYJrUePHlWHDh1qVH9d/5dc586d9f33358z1NRUhw4dtHPnzirtBQUFzvWX2quvvqpBgwbphRdecGk/evRojT7UOnfuLEn6/PPPq33PKkNEw4YNz/u+Vj6vZu/everZs6ezvfI2/6lTp2rgwIEu2zgcDo0bN06rV69WamqqS03uzjZeaN3S2TNK7i43/vQM5Lm8+uqr6tSpk3Jyclz+fPz00k/nzp21ceNGffvtt+c8y2K32zVmzBi9+OKLeuyxx7Ru3TpNmjTJbbisPEv7v3/GUb8whwVecfLkSeXk5Gj48OEaOXJklWXq1Kk6fvx4lVtBK9ntdsXHx2vdunX6+uuvne27d++u8kTQYcOGSVKVR8ZnZGRIkm655ZYaHUPlNfSjR4/WaHtvu/POO7Vt2zZt3LixyrqjR4/qzJkzNR572LBh2r59u7Zt2+ZsKysr03PPPaewsDB169atxmNfKLvdXuWMwSuvvOKcQ+Kp6OhodezYUZmZmVV+5pX7adWqlW688UYtXbpUBw8erDJG5e3kkhQTEyNfX1/nbbyVKs+uPPLII1X+XNx5550aOHCgs8/gwYPVtGlTpaen69SpU25rupC6pbMhoqCgwKXGTz/9VP/85z8v5O2R9ONZqv8d94MPPnD5PZDOzn8xxuh3v/tdlTF++jMbN26cvvvuO91zzz36/vvvNXbsWLf7zsvLU1BQkLp3737B9aJu4QwLvOKNN97Q8ePH9ctf/tLt+p/97GfOh8iNGjXKbZ+5c+fq73//u/r37697771XFRUVWrRokXr06KFPPvnE2a9Xr15KTEzUc889p6NHj2rgwIHavn27VqxYoREjRjgn/HoqKipKdrtdjz32mI4dOyY/Pz/9/Oc/d5knYmUPP/yw3njjDQ0fPlwTJkxQTEyMysrK9Nlnn+nVV1/Vvn37anx6PSUlRS+99JKGDh2qadOmqUWLFlqxYoX27t2r1157zTkZ9lIaPny45s2bp6SkJMXFxemzzz7TqlWranwpxcfHR88++6wSEhIUFRWlpKQktWnTRgUFBfrPf/7jDH5ZWVkaMGCAevbsqUmTJqlTp04qKSnRtm3b9N///tf5HBh/f38NHjxY77zzjubNm+fcz6pVqxQVFVVl/lKlX/7yl7r//vuVn5+v6Oho/eEPf9DEiRN13XXXacyYMWrevLk+/fRTnThxQitWrLjguu+66y5lZGRoyJAhuvvuu3Xo0CEtWbJE3bt3V2lp6QW/5zk5Obrtttt0yy23aO/evVqyZIm6devm8l1JgwYN0rhx4/THP/5RhYWFuvnmm+VwOPTee+9p0KBBmjp1qrNv79691aNHD73yyiuKjIxUdHS0232//fbbSkhIqPNnPnEOl/2+JMCcvSXZ39/flJWVVdtnwoQJpmHDhubIkSPGmKq3NRtjTG5urundu7fx9fU1nTt3Nn/605/MjBkzjL+/v0u/H374wfzud78zHTt2NA0bNjShoaFm5syZLreeGnP2duRbbrnFbT0/va3ZmLPPiujUqZOx2+0utzhXN85Pbx2tvK35ww8/dOk3Z84cI8kcPnzYpT0xMdE0btzYbX0/3Y+757D81PHjx83MmTNNly5djK+vr2nZsqWJi4szTz75pDl9+rQx5sfbWJ944gm3Y8jNbc3GnH1WzciRI02zZs2Mv7+/6du3r3nzzTdd+lTeUvzKK69U2b66Y63u2H76np86dcrMmDHDtGnTxgQEBJj+/fubbdu2VfkZVFdD5XEvX77cpX3r1q3mpptuMk2bNjWNGzc21157rfPZIf977OPHjzetW7c2DRs2NO3atTPDhw83r776qku/nJwcl2et5OXlGUkmLS2tyvFV2rdvn5Fkpk+f7mx74403TFxcnAkICDCBgYGmb9++5qWXXvK47uzsbNOpUyfj6+troqKizMaNG6u9rdnd74PD4TALFy40HTp0MH5+fqZ3797mzTffrDKGMWdvgX7iiSdMRESE8fX1NcHBwWbo0KEmLy+vyriPP/54lVvc/9eOHTuMJPPOO+9U+76h7rMZw2MBUb+MGDFC//nPf1RYWOjtUoBzqqioULdu3XTnnXdq/vz53i7Hsp5++mlNnz5d+/btc3v33YMPPqh3331XeXl5nGGpx5jDgjqt8nt+KhUWFmr9+vVuHzEOWI3dbte8efOUlZXlcskEPzLG6IUXXtDAgQPdhpVvvvlGf/rTn/T//t//I6zUc5xhQZ3Wpk0bTZgwQZ06ddL+/fv17LPPqry8XB9//LG6du3q7fIA1FBZWZneeOMNbd68Wc8//7z+8pe/VDvnDVcGAgvqtKSkJG3evFnFxcXy8/NTv379tHDhwmon5gGoG/bt26eOHTuqWbNm+u1vf6sFCxZ4uyR4GYEFAABYHnNYAACA5dWb57A4HA59/fXXatq0KROvAACoI4wxOn78uNq2bXvOZzTVm8Dy9ddfV/ugJQAAYG1fffVVle/V+l/1JrA0bdpU0tkDDgwM9HI1AADgQpSWlio0NNT5OV6dehNYKi8DBQYGElgAAKhjzjedg0m3AADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8ggsAADA8urNtzWjfjhx4oQKCgrO2+/kyZPat2+fwsLCFBAQcM6+ERERatSoUW2VCADwAgILLKWgoEAxMTG1OmZeXp6io6NrdUwAwOVFYIGlREREKC8v77z9duzYobFjxyo7O1uRkZHnHRMAULfVKLBkZWXpiSeeUHFxsXr16qVnnnlGffv2ddv3hx9+UHp6ulasWKGioiKFh4frscce08033+zs8+677+qJJ55QXl6eDh48qNdff10jRoyo0QGhbmvUqJFHZ0MiIyM5ewIAVwCPJ92uXbtWycnJmjNnjvLz89WrVy8NGTJEhw4dcts/NTVVS5cu1TPPPKMvvvhCU6ZM0W233aaPP/7Y2aesrEy9evVSVlZWzY8EAADUWzZjjPFkg9jYWF133XVatGiRJMnhcCg0NFT333+/UlJSqvRv27atHn30Ud13333Otttvv10BAQHKzs6uWpDNVqMzLKWlpQoKCtKxY8cUGBjo0baoe/Lz8xUTE8P8FACo4y7089ujMyynT59WXl6e4uPjfxzAx0fx8fHatm2b223Ky8vl7+/v0hYQEKCtW7d6smu345aWlrosAACgfvIosBw5ckQVFRUKCQlxaQ8JCVFxcbHbbYYMGaKMjAwVFhbK4XDo7bffVk5Ojg4ePFjzqiWlp6crKCjIuYSGhl7UeAAAwLou+YPjnn76aXXt2lURERHy9fXV1KlTlZSUJB+fi9v1zJkzdezYMefy1Vdf1VLFAADAajxKDS1btpTdbldJSYlLe0lJiVq3bu12m+DgYK1bt05lZWXav3+/CgoK1KRJE3Xq1KnmVUvy8/NTYGCgywIAAOonjwKLr6+vYmJilJub62xzOBzKzc1Vv379zrmtv7+/2rVrpzNnzui1117TrbfeWrOKAQDAFcfj57AkJycrMTFRffr0Ud++fZWZmamysjIlJSVJksaPH6927dopPT1dkvTBBx+oqKhIUVFRKioq0ty5c+VwOPTII484x/z++++1e/du5+u9e/fqk08+UYsWLXT11Vdf7DECAIA6zuPAMmrUKB0+fFizZ89WcXGxoqKitGHDBudE3AMHDrjMTzl16pRSU1O1Z88eNWnSRMOGDdPKlSvVrFkzZ5+PPvpIgwYNcr5OTk6WJCUmJurFF1+s4aEBAID6wuPnsFgVz2G5svAcFgCoHy7Jc1gAAAC8gcACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsj8ACAAAsr4G3C8CVpbCwUMePH7/ocXbs2OHy34vRtGlTde3a9aLHAQBcOgQWXDaFhYW65ppranXMsWPH1so4u3btIrQAgIURWHDZVJ5Zyc7OVmRk5EWNdfLkSe3bt09hYWEKCAio8Tg7duzQ2LFja+WsDwDg0iGw4LKLjIxUdHT0RY/Tv3//WqgGAFAXMOkWAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYHoEFAABYXo0CS1ZWlsLCwuTv76/Y2Fht37692r4//PCD5s2bp86dO8vf31+9evXShg0bLmpMAABwZfE4sKxdu1bJycmaM2eO8vPz1atXLw0ZMkSHDh1y2z81NVVLly7VM888oy+++EJTpkzRbbfdpo8//rjGYwIAgCuLx4ElIyNDkyZNUlJSkrp166YlS5aoUaNGWrZsmdv+K1eu1KxZszRs2DB16tRJ9957r4YNG6annnqqxmNKUnl5uUpLS10WAABQP3kUWE6fPq28vDzFx8f/OICPj+Lj47Vt2za325SXl8vf39+lLSAgQFu3bq3xmJKUnp6uoKAg5xIaGurJoQAAgDrEo8By5MgRVVRUKCQkxKU9JCRExcXFbrcZMmSIMjIyVFhYKIfDobfffls5OTk6ePBgjceUpJkzZ+rYsWPO5auvvvLkUAAAQB1yye8Sevrpp9W1a1dFRETI19dXU6dOVVJSknx8Lm7Xfn5+CgwMdFkAAED95FFqaNmypex2u0pKSlzaS0pK1Lp1a7fbBAcHa926dSorK9P+/ftVUFCgJk2aqFOnTjUeEwAAXFk8Ciy+vr6KiYlRbm6us83hcCg3N1f9+vU757b+/v5q166dzpw5o9dee0233nrrRY8JAACuDA083SA5OVmJiYnq06eP+vbtq8zMTJWVlSkpKUmSNH78eLVr107p6emSpA8++EBFRUWKiopSUVGR5s6dK4fDoUceeeSCxwQAAFc2jwPLqFGjdPjwYc2ePVvFxcWKiorShg0bnJNmDxw44DI/5dSpU0pNTdWePXvUpEkTDRs2TCtXrlSzZs0ueEwAAHBlsxljjLeLqA2lpaUKCgrSsWPHmIBrUfn5+YqJiVFeXp6io6O9XY4ka9YEAFeSC/385ruEAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5TXwdgG4srRuYlPA0V3S19bIygFHd6l1E5u3ywAAnAeBBZfVPTG+inz3Huldb1dyVqTO1gQAsDYCCy6rpXmnNWr2i4qMiPB2KZKkHQUFWvrUGP3S24UAAM6JwILLqvh7o5PNrpHaRnm7FEnSyWKHir833i4DAHAe1phIAAAAcA4EFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHkEFgAAYHk1CixZWVkKCwuTv7+/YmNjtX379nP2z8zMVHh4uAICAhQaGqrp06fr1KlTzvXHjx/Xgw8+qA4dOiggIEBxcXH68MMPa1IaAACohzwOLGvXrlVycrLmzJmj/Px89erVS0OGDNGhQ4fc9l+9erVSUlI0Z84c7dixQy+88ILWrl2rWbNmOftMnDhRb7/9tlauXKnPPvtMgwcPVnx8vIqKimp+ZAAAoN7wOLBkZGRo0qRJSkpKUrdu3bRkyRI1atRIy5Ytc9v//fffV//+/TVmzBiFhYVp8ODBGj16tPOszMmTJ/Xaa6/p8ccf1w033KAuXbpo7ty56tKli5599tlq6ygvL1dpaanLAgAA6iePAsvp06eVl5en+Pj4Hwfw8VF8fLy2bdvmdpu4uDjl5eU5A8qePXu0fv16DRs2TJJ05swZVVRUyN/f32W7gIAAbd26tdpa0tPTFRQU5FxCQ0M9ORQAAFCHeBRYjhw5ooqKCoWEhLi0h4SEqLi42O02Y8aM0bx58zRgwAA1bNhQnTt31o033ui8JNS0aVP169dP8+fP19dff62KigplZ2dr27ZtOnjwYLW1zJw5U8eOHXMuX331lSeHAgAA6pBLfpfQli1btHDhQi1evFj5+fnKycnRW2+9pfnz5zv7rFy5UsYYtWvXTn5+fvrjH/+o0aNHy8en+vL8/PwUGBjosgAAgPqpgSedW7ZsKbvdrpKSEpf2kpIStW7d2u02aWlpGjdunCZOnChJ6tmzp8rKyjR58mQ9+uij8vHxUefOnfWPf/xDZWVlKi0tVZs2bTRq1Ch16tSphocFAADqE4/OsPj6+iomJka5ubnONofDodzcXPXr18/tNidOnKhypsRut0uSjDEu7Y0bN1abNm303XffaePGjbr11ls9KQ8AANRTHp1hkaTk5GQlJiaqT58+6tu3rzIzM1VWVqakpCRJ0vjx49WuXTulp6dLkhISEpSRkaHevXsrNjZWu3fvVlpamhISEpzBZePGjTLGKDw8XLt379bDDz+siIgI55gAAODK5nFgGTVqlA4fPqzZs2eruLhYUVFR2rBhg3Mi7oEDB1zOqKSmpspmsyk1NVVFRUUKDg5WQkKCFixY4Oxz7NgxzZw5U//973/VokUL3X777VqwYIEaNmxYC4cIAADqOpv56XWZOqq0tFRBQUE6duwYE3AtKj8/XzExMcrLy1N0dLS3y5FkzZoA4EpyoZ/fHp9hAWrqxIkTks6GhOqcPHlS+/btq9X9hoWFKSAgwO26HTt21Oq+AACXBoEFl01BQYEkadKkSV6upKqmTZt6uwQAwDkQWHDZjBgxQpIUERGhRo0aue1zuc+wSGfDSteuXWt1nwCA2sUcFgAA4DUX+vl9yZ90CwAAcLEILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPJqFFiysrIUFhYmf39/xcbGavv27efsn5mZqfDwcAUEBCg0NFTTp0/XqVOnnOsrKiqUlpamjh07KiAgQJ07d9b8+fNljKlJeQAAoJ5p4OkGa9euVXJyspYsWaLY2FhlZmZqyJAh2rlzp1q1alWl/+rVq5WSkqJly5YpLi5Ou3bt0oQJE2Sz2ZSRkSFJeuyxx/Tss89qxYoV6t69uz766CMlJSUpKChI06ZNu/ijBAAAdZrNeHgaIzY2Vtddd50WLVokSXI4HAoNDdX999+vlJSUKv2nTp2qHTt2KDc319k2Y8YMffDBB9q6daskafjw4QoJCdELL7zg7HP77bcrICBA2dnZbusoLy9XeXm583VpaalCQ0N17NgxBQYGenJIAADAS0pLSxUUFHTez2+PLgmdPn1aeXl5io+P/3EAHx/Fx8dr27ZtbreJi4tTXl6e87LRnj17tH79eg0bNsylT25urnbt2iVJ+vTTT7V161YNHTq02lrS09MVFBTkXEJDQz05FAAAUId4dEnoyJEjqqioUEhIiEt7SEiICgoK3G4zZswYHTlyRAMGDJAxRmfOnNGUKVM0a9YsZ5+UlBSVlpYqIiJCdrtdFRUVWrBggX7zm99UW8vMmTOVnJzsfF15hgUAANQ/l/wuoS1btmjhwoVavHix8vPzlZOTo7feekvz58939nn55Ze1atUqrV69Wvn5+VqxYoWefPJJrVixotpx/fz8FBgY6LIAAID6yaMzLC1btpTdbldJSYlLe0lJiVq3bu12m7S0NI0bN04TJ06UJPXs2VNlZWWaPHmyHn30Ufn4+Ojhhx9WSkqKfv3rXzv77N+/X+np6UpMTKzJcQEAgHrEozMsvr6+iomJcZlA63A4lJubq379+rnd5sSJE/Lxcd2N3W6XJOdty9X1cTgcnpQHAADqKY9va05OTlZiYqL69Omjvn37KjMzU2VlZUpKSpIkjR8/Xu3atVN6erokKSEhQRkZGerdu7diY2O1e/dupaWlKSEhwRlcEhIStGDBAl199dXq3r27Pv74Y2VkZOiuu+6qxUMFAAB1lceBZdSoUTp8+LBmz56t4uJiRUVFacOGDc6JuAcOHHA5W5KamiqbzabU1FQVFRUpODjYGVAqPfPMM0pLS9Nvf/tbHTp0SG3bttU999yj2bNn18IhAgCAus7j57BY1YXexw0AAKzjkjyHBQAAwBsILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPIILAAAwPJqFFiysrIUFhYmf39/xcbGavv27efsn5mZqfDwcAUEBCg0NFTTp0/XqVOnnOvDwsJks9mqLPfdd19NygMAAPVMA083WLt2rZKTk7VkyRLFxsYqMzNTQ4YM0c6dO9WqVasq/VevXq2UlBQtW7ZMcXFx2rVrlyZMmCCbzaaMjAxJ0ocffqiKigrnNp9//rluuukm3XHHHRdxaAAAoL6wGWOMJxvExsbquuuu06JFiyRJDodDoaGhuv/++5WSklKl/9SpU7Vjxw7l5uY622bMmKEPPvhAW7dudbuPBx98UG+++aYKCwtls9nc9ikvL1d5ebnzdWlpqUJDQ3Xs2DEFBgZ6ckgAAMBLSktLFRQUdN7Pb48uCZ0+fVp5eXmKj4//cQAfH8XHx2vbtm1ut4mLi1NeXp7zstGePXu0fv16DRs2rNp9ZGdn66677qo2rEhSenq6goKCnEtoaKgnhwIAAOoQjy4JHTlyRBUVFQoJCXFpDwkJUUFBgdttxowZoyNHjmjAgAEyxujMmTOaMmWKZs2a5bb/unXrdPToUU2YMOGctcycOVPJycnO15VnWAAAQP1zye8S2rJlixYuXKjFixcrPz9fOTk5euuttzR//ny3/V944QUNHTpUbdu2Pee4fn5+CgwMdFkAAED95NEZlpYtW8put6ukpMSlvaSkRK1bt3a7TVpamsaNG6eJEydKknr27KmysjJNnjxZjz76qHx8fsxM+/fv1zvvvKOcnBxPjwMAANRjHp1h8fX1VUxMjMsEWofDodzcXPXr18/tNidOnHAJJZJkt9slST+d77t8+XK1atVKt9xyiydlAQCAes7j25qTk5OVmJioPn36qG/fvsrMzFRZWZmSkpIkSePHj1e7du2Unp4uSUpISFBGRoZ69+6t2NhY7d69W2lpaUpISHAGF+ls8Fm+fLkSExPVoIHHZQEAgHrM42QwatQoHT58WLNnz1ZxcbGioqK0YcMG50TcAwcOuJxRSU1Nlc1mU2pqqoqKihQcHKyEhAQtWLDAZdx33nlHBw4c0F133XWRhwQAAOobj5/DYlUXeh83AACwjkvyHBYAAABvILAAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLI7AAAADLa+DtAgAAV4YTJ06ooKDgvP1Onjypffv2KSwsTAEBAefsGxERoUaNGtVWibAwAgsA4LIoKChQTExMrY6Zl5en6OjoWh0T1kRgAQBcFhEREcrLyztvvx07dmjs2LHKzs5WZGTkecfElYHAAgCoFYWFhTp+/Phl3ef5LjE1bdpUXbt2vUzV4FIisAAALlphYaGuueaaWh1z7NixtTLOrl27CC31AIEFAHDRKs+sXMhlnPPxZNLtuVReWrrcZ31waRBYAAC1JjIyslYmwfbv378WqkF9wnNYAACA5RFYAACA5RFYAACA5RFYAACA5RFYAACA5dUosGRlZSksLEz+/v6KjY3V9u3bz9k/MzNT4eHhCggIUGhoqKZPn65Tp0659CkqKtLYsWN11VVXKSAgQD179tRHH31Uk/IAAEA94/FtzWvXrlVycrKWLFmi2NhYZWZmasiQIdq5c6datWpVpf/q1auVkpKiZcuWKS4uTrt27dKECRNks9mUkZEhSfruu+/Uv39/DRo0SH/7298UHByswsJCNW/e/OKPEAAA1HkeB5aMjAxNmjRJSUlJkqQlS5borbfe0rJly5SSklKl//vvv6/+/ftrzJgxkqSwsDCNHj1aH3zwgbPPY489ptDQUC1fvtzZ1rFjR48PBgAA1E8eXRI6ffq08vLyFB8f/+MAPj6Kj4/Xtm3b3G4TFxenvLw852WjPXv2aP369Ro2bJizzxtvvKE+ffrojjvuUKtWrdS7d289//zz56ylvLxcpaWlLgsAAKifPAosR44cUUVFhUJCQlzaQ0JCVFxc7HabMWPGaN68eRowYIAaNmyozp0768Ybb9SsWbOcffbs2aNnn31WXbt21caNG3Xvvfdq2rRpWrFiRbW1pKenKygoyLmEhoZ6cigAAKAOueR3CW3ZskULFy7U4sWLlZ+fr5ycHL311luaP3++s4/D4VB0dLQWLlyo3r17a/LkyZo0aZKWLFlS7bgzZ87UsWPHnMtXX311qQ8FAAB4iUdzWFq2bCm73a6SkhKX9pKSErVu3drtNmlpaRo3bpwmTpwoSerZs6fKyso0efJkPfroo/Lx8VGbNm3UrVs3l+0iIyP12muvVVuLn5+f/Pz8PCkfAADUUR6dYfH19VVMTIxyc3OdbQ6HQ7m5uerXr5/bbU6cOCEfH9fd2O12SZIxRtLZL7nauXOnS59du3apQ4cOnpQHAADqKY/vEkpOTlZiYqL69Omjvn37KjMzU2VlZc67hsaPH6927dopPT1dkpSQkKCMjAz17t1bsbGx2r17t9LS0pSQkOAMLtOnT1dcXJwWLlyoO++8U9u3b9dzzz2n5557rhYPFQAA1FUeB5ZRo0bp8OHDmj17toqLixUVFaUNGzY4J+IeOHDA5YxKamqqbDabUlNTVVRUpODgYCUkJGjBggXOPtddd51ef/11zZw5U/PmzVPHjh2VmZmp3/zmN7VwiAAAoK6zmcrrMnVcaWmpgoKCdOzYMQUGBnq7HAC4ouTn5ysmJkZ5eXmKjo72djmSrFkTqrrQz2++SwgAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFgegQUAAFheA28XAACoH1o3sSng6C7pa2v8Wzjg6C61bmLzdhmoJQQW1DkVFRV67733dPDgQbVp00bXX3+97Ha7t8sCrnj3xPgq8t17pHe9XclZkTpbE+oHAgvqlJycHM2YMUP79u1ztoWFhempp57Sr371K+8VBlzhTpw4oaV5p9XrzhRFRERc1Fjl5eX6+uuv1bZtW/n5+dV4nL1792pp3qP65UVVA6sgsKDOyMnJ0ciRIzV8+HC99NJL6tGjhz7//HMtXLhQI0eO1KuvvkpoAbykoKBAxd8b/eq+33m7lCqaNm3q7RJQC2zGGOPtImpDaWmpgoKCdOzYMQUGBnq7HNSyiooKdenSRT179tS6devk4/PjNXKHw6ERI0bo888/V2FhIZeHAC84cuSI1q1bp4iICDVq1OiixtqxY4fGjh2r7OxsRUZGXtRYTZs2VdeuXS9qDFxaF/r5zRkW1Anvvfee9u3bp5deesklrEiSj4+PZs6cqbi4OL333nu68cYbvVMkcAVr2bKlJk6cWKtjRkZGKjo6ulbHRN1ljancwHkcPHhQktSjRw+36yvbK/sBAOoXAgvqhDZt2kiSPv/8c7frK9sr+wEA6hcCC+qE66+/XmFhYVq4cKEcDofLOofDofT0dHXs2FHXX3+9lyoEAFxKBBbUCXa7XU899ZTefPNNjRgxQtu2bdPx48e1bds2jRgxQm+++aaefPJJJtwCQD3FpFvUGb/61a/06quvasaMGYqLi3O2d+zYkVuaAaCeI7CgTvnVr36lW2+9lSfdAsAVhsCCOsdut3PrMgBcYZjDAgAALI8zLACAy+LEiRMqKCg4b78dO3a4/PdcauPJuqgbCCwAgMuioKBAMTExF9x/7Nix5+2Tl5fH03CvEAQWAMBlERERoby8vPP2O3nypPbt26ewsDAFBAScd0xcGfjyQwAA4DUX+vnNpFsAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5BBYAAGB5NQosWVlZCgsLk7+/v2JjY7V9+/Zz9s/MzFR4eLgCAgIUGhqq6dOn69SpU871c+fOlc1mc1n4fggAAFDJ4y8/XLt2rZKTk7VkyRLFxsYqMzNTQ4YM0c6dO9WqVasq/VevXq2UlBQtW7ZMcXFx2rVrlyZMmCCbzaaMjAxnv+7du+udd975sbAGfC8jAAA4y+MzLBkZGZo0aZKSkpLUrVs3LVmyRI0aNdKyZcvc9n///ffVv39/jRkzRmFhYRo8eLBGjx5d5axMgwYN1Lp1a+fSsmXLmh0RAACodzw6jXH69Gnl5eVp5syZzjYfHx/Fx8dr27ZtbreJi4tTdna2tm/frr59+2rPnj1av369xo0b59KvsLBQbdu2lb+/v/r166f09HRdffXV1dZSXl6u8vJy5+tjx45JOvutjwAAoG6o/Nw2xpy7o/FAUVGRkWTef/99l/aHH37Y9O3bt9rtnn76adOwYUPToEEDI8lMmTLFZf369evNyy+/bD799FOzYcMG069fP3P11Veb0tLSasecM2eOkcTCwsLCwsJSD5avvvrqnBnkkk8U2bJlixYuXKjFixcrNjZWu3fv1gMPPKD58+crLS1NkjR06FBn/2uvvVaxsbHq0KGDXn75Zd19991ux505c6aSk5Odrx0Oh7799ltdddVVstlsl/ag4HWlpaUKDQ3VV199pcDAQG+XA6AW8ef7ymKM0fHjx9W2bdtz9vMosLRs2VJ2u10lJSUu7SUlJWrdurXbbdLS0jRu3DhNnDhRktSzZ0+VlZVp8uTJevTRR+XjU3UaTbNmzXTNNddo9+7d1dbi5+cnPz+/KtvhyhIYGMhfaEA9xZ/vK0dQUNB5+3g06dbX11cxMTHKzc11tjkcDuXm5qpfv35utzlx4kSVUGK32yWp2utV33//vb788ku1adPGk/IAAEA95fEloeTkZCUmJqpPnz7q27evMjMzVVZWpqSkJEnS+PHj1a5dO6Wnp0uSEhISlJGRod69ezsvCaWlpSkhIcEZXB566CElJCSoQ4cO+vrrrzVnzhzZ7XaNHj26Fg8VAADUVR4HllGjRunw4cOaPXu2iouLFRUVpQ0bNigkJESSdODAAZczKqmpqbLZbEpNTVVRUZGCg4OVkJCgBQsWOPv897//1ejRo/XNN98oODhYAwYM0L/+9S8FBwfXwiGiPvLz89OcOXOqXBYEUPfx5xvu2Ex112UAAAAsgu8SAgAAlkdgAQAAlkdgAQAAlkdgAQAAlkdgAQAAlkdgAQAAlkdgAQAAlnfJv/wQqE2FhYXavHmzDh06JIfD4bJu9uzZXqoKQG356KOPtGPHDklSZGSk+vTp4+WKYBU8OA51xvPPP697771XLVu2VOvWrV2+ldtmsyk/P9+L1QG4GJVPPP/nP//p/CLbo0ePKi4uTmvWrFH79u29WyC8jsCCOqNDhw767W9/q//7v//zdikAatnNN9+so0ePasWKFQoPD5ck7dy5U0lJSQoMDNSGDRu8XCG8jcCCOiMwMFCffPKJOnXq5O1SANSygIAAvf/+++rdu7dLe15enq6//nqdOHHCS5XBKph0izrjjjvu0N///ndvlwHgEggNDdUPP/xQpb2iokJt27b1QkWwGibdos7o0qWL0tLS9K9//Us9e/ZUw4YNXdZPmzbNS5UBuFhPPPGE7r//fmVlZTkn2n700Ud64IEH9OSTT3q5OlgBl4RQZ3Ts2LHadTabTXv27LmM1QCoTc2bN9eJEyd05swZNWhw9t/Slf/fuHFjl77ffvutN0qEl3GGBXXG3r17vV0CgEskMzPT2yXA4jjDAgAALI8zLKgzKioq9OKLLyo3N9ftg+M2bdrkpcoA1ERpaekF9w0MDLyElaAuILCgznjggQf04osv6pZbblGPHj1cHhwHoO5p1qzZef8cG2Nks9lUUVFxmaqCVRFYUGesWbNGL7/8soYNG+btUgDUgs2bN3u7BNQhBBbUGb6+vurSpYu3ywBQSwYOHOjy+tSpU/r3v//t9pIvwKRb1BlPPfWU9uzZo0WLFnE5CKhnNmzYoPHjx+vIkSNV1nFJCBKBBXXIbbfdps2bN6tFixbq3r17lQfH5eTkeKkyABera9euGjx4sGbPnq2QkBBvlwML4pIQ6oxmzZrptttuc7uOMy5A3VZSUqLk5GTCCqpFYEGdMXjwYI0ePdrtuocffvgyVwOgNo0cOVJbtmxR586dvV0KLIpLQqgzmjVrppdeeklDhw51aU9OTtZLL72kgwcPeqkyABfrxIkTuuOOOxQcHMx3hcEtAgvqjLfeeku/+c1v9Oabb2rAgAGSpPvvv1+vvfaaNm3apIiICC9XCKCmXnjhBU2ZMkX+/v666qqrXC7z8l1hkAgsqGNWr16tqVOn6u2339YLL7ygv/zlL9q8ebOuueYab5cG4CK0bt1a06ZNU0pKinx8fLxdDiyIOSyoU8aMGaOjR4+qf//+Cg4O1j/+8Q+ezQLUA6dPn9aoUaMIK6gWZ1hgacnJyW7bX3nlFUVHR7tM0MvIyLhcZQGoZdOnT1dwcLBmzZrl7VJgUZxhgaV9/PHHbtu7dOmi0tJS53puawbqtoqKCj3++OPauHGjrr322iqTbvkHCTjDAgDwukGDBlW7zmaz8W3sILAAAADrY3YTAACwPAILAACwPAILAACwPAILAACwPAILAACwPAILAACwPAILAACwvP8PvL+7NNqhkfcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "model_comp = []\n",
        "model_comp.append(knn_acc_score)\n",
        "model_comp.append(mlp_acc_score)\n",
        "\n",
        "fig, ax2 = plt.pyplot.subplots()\n",
        "ax2.set_title('Algorithm Performance(Accuracy)')\n",
        "ax2.boxplot(model_comp)\n",
        "ax2.set_xticklabels(['knn', 'mlp'], rotation='vertical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at this, the MLP is the better algorithm for consistency in accuracy, but the kNN has the capability to produce higher accuracy scores with more variability."
      ],
      "metadata": {
        "id": "WGP8f2ephu7b"
      },
      "id": "WGP8f2ephu7b"
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp = []\n",
        "model_comp.append(knn_f1_score)\n",
        "model_comp.append(mlp_f1_score)\n",
        "\n",
        "fig, ax2 = plt.pyplot.subplots()\n",
        "ax2.set_title('Algorithm Performance (f1 Score)')\n",
        "ax2.boxplot(model_comp)\n",
        "ax2.set_xticklabels(['knn', 'mlp'], rotation='vertical')"
      ],
      "metadata": {
        "id": "pjBpbT9BvSIA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "ea960bad-7457-481a-d48e-2a79c3b01a93"
      },
      "id": "pjBpbT9BvSIA",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(1, 0, 'knn'), Text(2, 0, 'mlp')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the f1 Scores, this shows that the knn model balances out false positives and negatives much better than the mlp model, meaning that the knn is more consistent for this task."
      ],
      "metadata": {
        "id": "g3bDmchpznxf"
      },
      "id": "g3bDmchpznxf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the kNN is the better performing model with better accuracy scores and more consistent f1 scores. In this scenario, the mlp could be tested to find better layering options, however with the resources that are available and heaps of combinations, it would take an exceedingly long time.   "
      ],
      "metadata": {
        "id": "xlcCsuEy0IbX"
      },
      "id": "xlcCsuEy0IbX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative AI was used to support completion of this assessment. The GenAI tool Gemini was used for the purpose of editing.\n",
        "Where used for the purpose of supporting development, comments have been provided against relevant cells."
      ],
      "metadata": {
        "id": "A-vlNGcM2Icj"
      },
      "id": "A-vlNGcM2Icj"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}