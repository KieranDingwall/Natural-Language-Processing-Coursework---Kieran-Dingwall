{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KieranDingwall/Natural-Language-Processing-Coursework---Kieran-Dingwall/blob/main/NLP_Coursework_V2_(Colab_Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47b40ace",
      "metadata": {
        "id": "47b40ace"
      },
      "source": [
        "# Natural Language Processing Coursework"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f5dba9e",
      "metadata": {
        "id": "8f5dba9e"
      },
      "source": [
        "By Kieran Dingwall - Student Number: 2208619"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1528fb70",
      "metadata": {
        "id": "1528fb70"
      },
      "source": [
        "### Section 1 - Dataset Exploring and Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1dfaab51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dfaab51",
        "outputId": "8193640a-de1b-40b9-99b3-5110d4c1f994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "       Product ID                                      Product Title  \\\n",
            "0               1                    apple iphone 8 plus 64gb silver   \n",
            "1               2                apple iphone 8 plus 64 gb spacegrau   \n",
            "2               3  apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...   \n",
            "3               4                apple iphone 8 plus 64gb space grey   \n",
            "4               5  apple iphone 8 plus gold 5.5 64gb 4g unlocked ...   \n",
            "...           ...                                                ...   \n",
            "35306       47350  smeg fab28 60cm retro style right hand hinge f...   \n",
            "35307       47351  smeg fab28 60cm retro style left hand hinge fr...   \n",
            "35308       47352  smeg fab28 60cm retro style left hand hinge fr...   \n",
            "35309       47355     candy 60cm built under larder fridge cru160nek   \n",
            "35310       47358           neff k4316x7gb built under larder fridge   \n",
            "\n",
            "        Merchant ID   Cluster ID             Cluster Label   Category ID  \\\n",
            "0                 1            1  Apple iPhone 8 Plus 64GB          2612   \n",
            "1                 2            1  Apple iPhone 8 Plus 64GB          2612   \n",
            "2                 3            1  Apple iPhone 8 Plus 64GB          2612   \n",
            "3                 4            1  Apple iPhone 8 Plus 64GB          2612   \n",
            "4                 5            1  Apple iPhone 8 Plus 64GB          2612   \n",
            "...             ...          ...                       ...           ...   \n",
            "35306            59        47517          Smeg FAB28 Cream          2623   \n",
            "35307            59        47518            Smeg FAB28 Red          2623   \n",
            "35308            59        47519           Smeg FAB28 Pink          2623   \n",
            "35309           125        47524             Candy CRU16.0          2623   \n",
            "35310           179        47525                Neff K4316          2623   \n",
            "\n",
            "       Category Label  \n",
            "0       Mobile Phones  \n",
            "1       Mobile Phones  \n",
            "2       Mobile Phones  \n",
            "3       Mobile Phones  \n",
            "4       Mobile Phones  \n",
            "...               ...  \n",
            "35306         Fridges  \n",
            "35307         Fridges  \n",
            "35308         Fridges  \n",
            "35309         Fridges  \n",
            "35310         Fridges  \n",
            "\n",
            "[35311 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import io\n",
        "\n",
        "# Load Dataset\n",
        "from google.colab import files, drive #import colab functionality\n",
        "drive.mount(\"/content/drive\")\n",
        "path = '/content/drive/MyDrive/Uni/4th Year 1st Sem/Natural Language Processing/NLP Coursework/pricerunner_aggregate.csv' # May need to change path\n",
        "product_data = pd.read_csv(path)\n",
        "print(product_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4d101a63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d101a63",
        "outputId": "5d4ae23f-381d-4502-d8bb-0ca0b811e3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           Product Title  \\\n",
            "0                        apple iphone 8 plus 64gb silver   \n",
            "1                    apple iphone 8 plus 64 gb spacegrau   \n",
            "2      apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...   \n",
            "3                    apple iphone 8 plus 64gb space grey   \n",
            "4      apple iphone 8 plus gold 5.5 64gb 4g unlocked ...   \n",
            "...                                                  ...   \n",
            "35306  smeg fab28 60cm retro style right hand hinge f...   \n",
            "35307  smeg fab28 60cm retro style left hand hinge fr...   \n",
            "35308  smeg fab28 60cm retro style left hand hinge fr...   \n",
            "35309     candy 60cm built under larder fridge cru160nek   \n",
            "35310           neff k4316x7gb built under larder fridge   \n",
            "\n",
            "                  Cluster Label  Category Label  \n",
            "0      Apple iPhone 8 Plus 64GB   Mobile Phones  \n",
            "1      Apple iPhone 8 Plus 64GB   Mobile Phones  \n",
            "2      Apple iPhone 8 Plus 64GB   Mobile Phones  \n",
            "3      Apple iPhone 8 Plus 64GB   Mobile Phones  \n",
            "4      Apple iPhone 8 Plus 64GB   Mobile Phones  \n",
            "...                         ...             ...  \n",
            "35306          Smeg FAB28 Cream         Fridges  \n",
            "35307            Smeg FAB28 Red         Fridges  \n",
            "35308           Smeg FAB28 Pink         Fridges  \n",
            "35309             Candy CRU16.0         Fridges  \n",
            "35310                Neff K4316         Fridges  \n",
            "\n",
            "[35311 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Remove unused columns from data\n",
        "product_df = product_data.drop(product_data.columns[[0, 2, 3, 5]], axis=1)\n",
        "print(product_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ad46de17",
      "metadata": {
        "id": "ad46de17"
      },
      "outputs": [],
      "source": [
        "# Convert the feature columns into numpy array's\n",
        "x = product_df[\"Product Title\"].to_numpy()\n",
        "y = product_df[\" Category Label\"].to_numpy()\n",
        "\n",
        "# Testing outputs\n",
        "#print(x)\n",
        "#print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d9c2d08f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9c2d08f",
        "outputId": "801a42df-2a90-40a8-e2b5-33bdcc3a4f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Title\n",
            "washing machine                                     90\n",
            "built in fully integrated dishwasher                35\n",
            "frost free fridge freezer                           34\n",
            "washer dryer                                        24\n",
            "american fridge freezer                             22\n",
            "                                                    ..\n",
            "sony hx400v compact camera with 50x optical zoom     1\n",
            "sony hx400 20mp 50x zoom bridge camera               1\n",
            "sony cyber shot hx400 digital camera                 1\n",
            "sony cyber shot dsc hx400v digital camera            1\n",
            "x t3 body only silver                                1\n",
            "Name: count, Length: 30993, dtype: int64\n",
            " Category Label\n",
            "Fridge Freezers     5501\n",
            "Mobile Phones       4081\n",
            "Washing Machines    4044\n",
            "CPUs                3862\n",
            "Fridges             3584\n",
            "TVs                 3564\n",
            "Dishwashers         3424\n",
            "Digital Cameras     2697\n",
            "Microwaves          2342\n",
            "Freezers            2212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Checking Balance\n",
        "\n",
        "print(product_df[\"Product Title\"].value_counts())\n",
        "print(product_df[\" Category Label\"].value_counts())\n",
        "\n",
        "# Balance is good"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import nltk #import the natural language toolkit\n",
        "nltk.download('punkt') #download the package in nltk which supports tokenization\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords') #download the nltk package for stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize #import the tokenize package\n",
        "from nltk.corpus import stopwords #import the package from the corpus\n",
        "from nltk.stem.snowball import SnowballStemmer #import the snowball stemmer (also known as Porter2)\n",
        "\n",
        "\n",
        "class pre_process(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self):\n",
        "      return None #we do not need any parameters to instantiate this class\n",
        "\n",
        "    def fit(self, X, y=None): #both fit and transform expect the data instances and labels to be called - we do not use the labels, so set y=None\n",
        "        return self #as explained above, we will not use the fit method\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      prep_text = []\n",
        "      for x in X: #for each sentence in the whole dataset\n",
        "            token_text = word_tokenize(x) #tokenize the document\n",
        "            normd_text = [token.lower() for token in token_text if token.isalpha()] #list compression to apply some simple cleaning (lower case casting and punctuation removal) to tokenized terms\n",
        "\n",
        "            swr_text = [token for token in normd_text if token not in stopwords.words('english')] #list compression to remove any stopwords from our list\n",
        "\n",
        "            stemmer = SnowballStemmer(\"english\") #specify we are using the English stemming rules, as other languages are present in toolkit\n",
        "            prep_text += [[stemmer.stem(word) for word in swr_text]] #list compression for applying the stemmer\n",
        "\n",
        "      prep_sentences = [\" \".join(sentence) for sentence in prep_text] #we join the sentences back together to ensure compatibility with CountVec, which is doing some of it's own prep\n",
        "      return prep_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxkNcP-3xq0e",
        "outputId": "07b9109d-615e-452e-88a3-813409c458f4"
      },
      "id": "kxkNcP-3xq0e",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4b0061",
      "metadata": {
        "id": "ee4b0061"
      },
      "source": [
        "### Section 2 - Representation Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e42e6ead",
      "metadata": {
        "id": "e42e6ead"
      },
      "outputs": [],
      "source": [
        "# Representation Learner - Vectorising\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_base = TfidfVectorizer(max_features=2000).fit_transform(x)\n",
        "#print(tfidf_base)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7562a92c",
      "metadata": {
        "id": "7562a92c"
      },
      "source": [
        "### Section 3 - Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "93c5e230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93c5e230",
        "outputId": "ff9bd9b1-274c-4fbe-9dfd-8ba705db1d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8531044846893796\n"
          ]
        }
      ],
      "source": [
        "# Testing with K-Nearest Neighbour in a pipeline\n",
        "\n",
        "# SKLearn Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "knn_acc_score = []\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('prep', pre_process()),\n",
        "  ('vect', CountVectorizer()),\n",
        "  ('tfidf_base', TfidfTransformer()),\n",
        "  ('clf', KNeighborsClassifier(n_neighbors=5))\n",
        "])\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5)\n",
        "for train, test in kf.split(x,y):\n",
        "  x_train, x_test, y_train, y_test = x[train], x[test], y[train], y[test]\n",
        "\n",
        "  pipeline.fit(x_train, y_train)\n",
        "  predictions = pipeline.predict(x_test)\n",
        "  acc = accuracy_score(predictions, y_test)\n",
        "  knn_acc_score.append(acc)\n",
        "\n",
        "print(\"Accuracy:\", np.mean(knn_acc_score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "519e871e",
      "metadata": {
        "id": "519e871e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8f28ce-46d7-4f50-9c18-93a6e33fb674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.5737 - loss: 1.7506 - val_accuracy: 0.3628 - val_loss: 3.8784\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1273 - val_accuracy: 0.3915 - val_loss: 4.6818\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0746 - val_accuracy: 0.4000 - val_loss: 4.9781\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0593 - val_accuracy: 0.4046 - val_loss: 5.2249\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0596 - val_accuracy: 0.3931 - val_loss: 5.3658\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0530 - val_accuracy: 0.4179 - val_loss: 5.4933\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9771 - loss: 0.0545 - val_accuracy: 0.4034 - val_loss: 5.4936\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9801 - loss: 0.0500 - val_accuracy: 0.4124 - val_loss: 5.6458\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0495 - val_accuracy: 0.4094 - val_loss: 5.6937\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0484 - val_accuracy: 0.4225 - val_loss: 5.7620\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.1242\n",
            "Test results - Loss: 1.2255 - Accuracy: 86.27%\n",
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.6388 - loss: 1.7443 - val_accuracy: 0.3862 - val_loss: 3.8440\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.1303 - val_accuracy: 0.4080 - val_loss: 4.6583\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0752 - val_accuracy: 0.4018 - val_loss: 5.0961\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0608 - val_accuracy: 0.4097 - val_loss: 5.3187\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0541 - val_accuracy: 0.4212 - val_loss: 5.4370\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0602 - val_accuracy: 0.4090 - val_loss: 5.4998\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0504 - val_accuracy: 0.4143 - val_loss: 5.6586\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0525 - val_accuracy: 0.4039 - val_loss: 5.6655\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0531 - val_accuracy: 0.4142 - val_loss: 5.6165\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0527 - val_accuracy: 0.4090 - val_loss: 5.7781\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.1218\n",
            "Test results - Loss: 1.2175 - Accuracy: 85.97%\n",
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6310 - loss: 1.7478 - val_accuracy: 0.3788 - val_loss: 3.6976\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9714 - loss: 0.1239 - val_accuracy: 0.3897 - val_loss: 4.4937\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0737 - val_accuracy: 0.4035 - val_loss: 4.8622\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0593 - val_accuracy: 0.4156 - val_loss: 5.2131\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0579 - val_accuracy: 0.4147 - val_loss: 5.2155\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0546 - val_accuracy: 0.4103 - val_loss: 5.3182\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0535 - val_accuracy: 0.4039 - val_loss: 5.4255\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0493 - val_accuracy: 0.4173 - val_loss: 5.5096\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.0505 - val_accuracy: 0.4099 - val_loss: 5.6374\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9810 - loss: 0.0479 - val_accuracy: 0.3940 - val_loss: 5.7566\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.1210\n",
            "Test results - Loss: 1.2334 - Accuracy: 85.61%\n",
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5352 - loss: 1.7826 - val_accuracy: 0.3954 - val_loss: 3.4659\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.1277 - val_accuracy: 0.4039 - val_loss: 4.3659\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0681 - val_accuracy: 0.4200 - val_loss: 4.8128\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0606 - val_accuracy: 0.4044 - val_loss: 5.1373\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0555 - val_accuracy: 0.4101 - val_loss: 5.3116\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0524 - val_accuracy: 0.4161 - val_loss: 5.3881\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0501 - val_accuracy: 0.4147 - val_loss: 5.4300\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0490 - val_accuracy: 0.4274 - val_loss: 5.6683\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0512 - val_accuracy: 0.4181 - val_loss: 5.6663\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9782 - loss: 0.0523 - val_accuracy: 0.4255 - val_loss: 5.7987\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.1364\n",
            "Test results - Loss: 1.2364 - Accuracy: 85.98%\n",
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5282 - loss: 1.7686 - val_accuracy: 0.3924 - val_loss: 3.6921\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1324 - val_accuracy: 0.3903 - val_loss: 4.5319\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0777 - val_accuracy: 0.4037 - val_loss: 4.8820\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0619 - val_accuracy: 0.4103 - val_loss: 5.1516\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0563 - val_accuracy: 0.4122 - val_loss: 5.2130\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0551 - val_accuracy: 0.4191 - val_loss: 5.4385\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0525 - val_accuracy: 0.4136 - val_loss: 5.4969\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9798 - loss: 0.0524 - val_accuracy: 0.4219 - val_loss: 5.5533\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0528 - val_accuracy: 0.4142 - val_loss: 5.6325\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0503 - val_accuracy: 0.4205 - val_loss: 5.6797\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9730 - loss: 0.1279\n",
            "Test results - Loss: 1.2123 - Accuracy: 85.92%\n",
            "Accuracy: 0.8595054507255554\n"
          ]
        }
      ],
      "source": [
        "# Testing with Multi Layer Perception to compare accuracy scores\n",
        "# Tensorflow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# SKLearn Imports\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def mlp(input_dimension, num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_shape=(input_dimension,), activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "# Initialize acc_score list\n",
        "mlp_acc_score = []\n",
        "\n",
        "# Map string labels to integers for to_categorical and StratifiedKFold\n",
        "unique_labels = np.unique(y)\n",
        "label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
        "y_encoded = np.array([label_to_int[label] for label in y])\n",
        "\n",
        "NUM_CLASSES = len(unique_labels)\n",
        "TFIDF_MAX_FEATURES = 2000\n",
        "\n",
        "for train_index, test_index in kf.split(x, y_encoded):\n",
        "  x_train, x_test = x[train_index], x[test_index]\n",
        "  y_train_encoded, y_test_encoded = y_encoded[train_index], y_encoded[test_index]\n",
        "\n",
        "  # Initialize a new TfidfVectorizer for each fold to prevent data leakage\n",
        "  tfidf_vectorizer = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES)\n",
        "\n",
        "  x_train_transformed = tfidf_vectorizer.fit_transform(x_train)\n",
        "  x_train_dense = x_train_transformed.todense() # Convert to dense matrix for Keras\n",
        "\n",
        "  x_test_transformed = tfidf_vectorizer.transform(x_test)\n",
        "  x_test_dense = x_test_transformed.todense() # Convert to dense matrix for Keras\n",
        "\n",
        "  # Instantiate a new mlp model for each fold and ensure correct input/output dimensions\n",
        "  model = mlp(TFIDF_MAX_FEATURES, NUM_CLASSES)\n",
        "  y_train_one_hot = to_categorical(y_train_encoded, NUM_CLASSES) # Convert y to one hot vectors\n",
        "  y_test_one_hot = to_categorical(y_test_encoded, NUM_CLASSES)\n",
        "\n",
        "  # Configure the model and start training (using categorical_crossentropy for multi-class)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(x_train_dense, y_train_one_hot, epochs=10, batch_size=250, verbose=1, validation_split=0.2)\n",
        "\n",
        "  # Test the model after training\n",
        "  test_results = model.evaluate(x_test_dense, y_test_one_hot, verbose=1)\n",
        "  print(f'Test results - Loss: {test_results[0]:.4f} - Accuracy: {test_results[1]*100:.2f}%')\n",
        "\n",
        "  mlp_acc_score.append(test_results[1])\n",
        "\n",
        "print(\"Accuracy:\", np.mean(mlp_acc_score))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd7583e0",
      "metadata": {
        "id": "cd7583e0"
      },
      "source": [
        "### Section 4 - Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6683c333",
      "metadata": {
        "id": "6683c333"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy almost the exact same - expand this"
      ],
      "metadata": {
        "id": "WGP8f2ephu7b"
      },
      "id": "WGP8f2ephu7b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}